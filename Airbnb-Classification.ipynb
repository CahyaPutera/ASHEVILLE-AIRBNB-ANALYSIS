{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASHEVILLE AIRBNB SENTIMENT ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The purpose of this report is **to analyze customer reviews for Airbnb on Asheville, North Carolina, United States**. And act as a stepping stone **to know what the customers think of the service offered by Asheville's Airbnb, and this analysis could help to know if the hosts are providing good customer service or not**. The analysis progress would be separated on several notebook, and will cover from *data preprocessing, text preprocessing, topic modelling, visualization, model building, to model testing*. \n",
    "\n",
    "> This notebook specifically will only cover the **MODEL BUILDING** and **MODEL SELECTION** part.\n",
    "\n",
    "> The dataset contains the **detailed review data for listings in Asheville, North Carolina** compiled on **08 November, 2020**. The data are from the **Inside Airbnb site**, it is sourced from publicly available information, from the Airbnb site. The data has been analyzed, cleansed and aggregated where appropriate to faciliate public discussion. More on this data, and other similar data refers to this [link](http://insideairbnb.com/get-the-data.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORT LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data wrangling\n",
    "\n",
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "\n",
    "# data visualization\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# text processing\n",
    "\n",
    "import nltk\n",
    "import en_core_web_sm\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# modelling\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# filter warning\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OVERVIEW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "\n",
    "df = pd.read_csv('asheville-reviews-tokenized.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>listing_id</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>reviewer_id</th>\n",
       "      <th>reviewer_name</th>\n",
       "      <th>comments</th>\n",
       "      <th>comments_cleaned</th>\n",
       "      <th>comments_tokenized</th>\n",
       "      <th>compound_score</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>topics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>108061</td>\n",
       "      <td>553741</td>\n",
       "      <td>2011-09-21</td>\n",
       "      <td>822907</td>\n",
       "      <td>Pedro &amp; Katie</td>\n",
       "      <td>Lisa is superb hostess, she will treat you lik...</td>\n",
       "      <td>lisa superb hostess treat like family provide ...</td>\n",
       "      <td>treat family coziest little home experience ma...</td>\n",
       "      <td>0.8519</td>\n",
       "      <td>positive</td>\n",
       "      <td>home beautiful perfect space host</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>108061</td>\n",
       "      <td>683278</td>\n",
       "      <td>2011-11-01</td>\n",
       "      <td>236064</td>\n",
       "      <td>Tim</td>\n",
       "      <td>This was a lovely little place walking distanc...</td>\n",
       "      <td>lovely little place walking distance downtown ...</td>\n",
       "      <td>lovely little place distance downtown responsi...</td>\n",
       "      <td>0.8481</td>\n",
       "      <td>positive</td>\n",
       "      <td>quiet drive minute close downtown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>108061</td>\n",
       "      <td>714889</td>\n",
       "      <td>2011-11-13</td>\n",
       "      <td>1382707</td>\n",
       "      <td>Shane</td>\n",
       "      <td>Lisa was very nice to work with.  However, we ...</td>\n",
       "      <td>lisa nice work however realize house old norma...</td>\n",
       "      <td>work old case floor permanent renter squeaky f...</td>\n",
       "      <td>0.8176</td>\n",
       "      <td>positive</td>\n",
       "      <td>quiet drive minute close downtown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>108061</td>\n",
       "      <td>1766157</td>\n",
       "      <td>2012-07-21</td>\n",
       "      <td>416731</td>\n",
       "      <td>Brenda</td>\n",
       "      <td>I feel very lucky to have found this beautiful...</td>\n",
       "      <td>feel lucky found beautiful home asheville quie...</td>\n",
       "      <td>lucky beautiful home quiet clean guest gloriou...</td>\n",
       "      <td>0.9957</td>\n",
       "      <td>positive</td>\n",
       "      <td>room bed nice comfortable clean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>108061</td>\n",
       "      <td>2033065</td>\n",
       "      <td>2012-08-19</td>\n",
       "      <td>1858880</td>\n",
       "      <td>Lindsey</td>\n",
       "      <td>Great roomy little apartment, beautiful privat...</td>\n",
       "      <td>great roomy little apartment beautiful private...</td>\n",
       "      <td>great roomy little apartment beautiful private...</td>\n",
       "      <td>0.9351</td>\n",
       "      <td>positive</td>\n",
       "      <td>home beautiful perfect space host</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   listing_id       id        date  reviewer_id  reviewer_name  \\\n",
       "0      108061   553741  2011-09-21       822907  Pedro & Katie   \n",
       "1      108061   683278  2011-11-01       236064            Tim   \n",
       "2      108061   714889  2011-11-13      1382707          Shane   \n",
       "3      108061  1766157  2012-07-21       416731         Brenda   \n",
       "4      108061  2033065  2012-08-19      1858880        Lindsey   \n",
       "\n",
       "                                            comments  \\\n",
       "0  Lisa is superb hostess, she will treat you lik...   \n",
       "1  This was a lovely little place walking distanc...   \n",
       "2  Lisa was very nice to work with.  However, we ...   \n",
       "3  I feel very lucky to have found this beautiful...   \n",
       "4  Great roomy little apartment, beautiful privat...   \n",
       "\n",
       "                                    comments_cleaned  \\\n",
       "0  lisa superb hostess treat like family provide ...   \n",
       "1  lovely little place walking distance downtown ...   \n",
       "2  lisa nice work however realize house old norma...   \n",
       "3  feel lucky found beautiful home asheville quie...   \n",
       "4  great roomy little apartment beautiful private...   \n",
       "\n",
       "                                  comments_tokenized  compound_score  \\\n",
       "0  treat family coziest little home experience ma...          0.8519   \n",
       "1  lovely little place distance downtown responsi...          0.8481   \n",
       "2  work old case floor permanent renter squeaky f...          0.8176   \n",
       "3  lucky beautiful home quiet clean guest gloriou...          0.9957   \n",
       "4  great roomy little apartment beautiful private...          0.9351   \n",
       "\n",
       "  sentiment                             topics  \n",
       "0  positive  home beautiful perfect space host  \n",
       "1  positive  quiet drive minute close downtown  \n",
       "2  positive  quiet drive minute close downtown  \n",
       "3  positive    room bed nice comfortable clean  \n",
       "4  positive  home beautiful perfect space host  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show top 5\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 173892 entries, 0 to 173891\n",
      "Data columns (total 11 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   listing_id          173892 non-null  int64  \n",
      " 1   id                  173892 non-null  int64  \n",
      " 2   date                173892 non-null  object \n",
      " 3   reviewer_id         173892 non-null  int64  \n",
      " 4   reviewer_name       173892 non-null  object \n",
      " 5   comments            173892 non-null  object \n",
      " 6   comments_cleaned    173892 non-null  object \n",
      " 7   comments_tokenized  172705 non-null  object \n",
      " 8   compound_score      173892 non-null  float64\n",
      " 9   sentiment           173892 non-null  object \n",
      " 10  topics              173892 non-null  object \n",
      "dtypes: float64(1), int64(3), object(7)\n",
      "memory usage: 14.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# check info\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to check data summary\n",
    "\n",
    "def summary(df):\n",
    "    \n",
    "    columns = df.columns.to_list()\n",
    "    \n",
    "    dtypes = []\n",
    "    unique_counts = []\n",
    "    missing_counts = []\n",
    "    missing_percentages = []\n",
    "    total_counts = [df.shape[0]] * len(columns)\n",
    "\n",
    "    for col in columns:\n",
    "        dtype = str(df[col].dtype)\n",
    "        dtypes.append(dtype)\n",
    "        unique_count = df[col].nunique()\n",
    "        unique_counts.append(unique_count)\n",
    "        missing_count = df[col].isnull().sum()\n",
    "        missing_counts.append(missing_count)\n",
    "        missing_percentage = round((missing_count/df.shape[0]) * 100, 2)\n",
    "        missing_percentages.append(missing_percentage)\n",
    "\n",
    "    df_summary = pd.DataFrame({\n",
    "        \"column\": columns,\n",
    "        \"dtypes\": dtypes,\n",
    "        \"unique_count\": unique_counts,\n",
    "        \"missing_values\": missing_counts,\n",
    "        \"missing_percentage\": missing_percentages,\n",
    "        \"total_count\": total_counts,\n",
    "    })\n",
    "\n",
    "    return df_summary.sort_values(by=\"missing_percentage\", ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>dtypes</th>\n",
       "      <th>unique_count</th>\n",
       "      <th>missing_values</th>\n",
       "      <th>missing_percentage</th>\n",
       "      <th>total_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>comments_tokenized</td>\n",
       "      <td>object</td>\n",
       "      <td>161619</td>\n",
       "      <td>1187</td>\n",
       "      <td>0.68</td>\n",
       "      <td>173892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>listing_id</td>\n",
       "      <td>int64</td>\n",
       "      <td>2044</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>173892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id</td>\n",
       "      <td>int64</td>\n",
       "      <td>173892</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>173892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>date</td>\n",
       "      <td>object</td>\n",
       "      <td>2904</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>173892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>reviewer_id</td>\n",
       "      <td>int64</td>\n",
       "      <td>158449</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>173892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>reviewer_name</td>\n",
       "      <td>object</td>\n",
       "      <td>16279</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>173892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>comments</td>\n",
       "      <td>object</td>\n",
       "      <td>170971</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>173892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>comments_cleaned</td>\n",
       "      <td>object</td>\n",
       "      <td>168410</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>173892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>compound_score</td>\n",
       "      <td>float64</td>\n",
       "      <td>1841</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>173892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sentiment</td>\n",
       "      <td>object</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>173892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>topics</td>\n",
       "      <td>object</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>173892</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                column   dtypes  unique_count  missing_values  \\\n",
       "0   comments_tokenized   object        161619            1187   \n",
       "1           listing_id    int64          2044               0   \n",
       "2                   id    int64        173892               0   \n",
       "3                 date   object          2904               0   \n",
       "4          reviewer_id    int64        158449               0   \n",
       "5        reviewer_name   object         16279               0   \n",
       "6             comments   object        170971               0   \n",
       "7     comments_cleaned   object        168410               0   \n",
       "8       compound_score  float64          1841               0   \n",
       "9            sentiment   object             3               0   \n",
       "10              topics   object             5               0   \n",
       "\n",
       "    missing_percentage  total_count  \n",
       "0                 0.68       173892  \n",
       "1                 0.00       173892  \n",
       "2                 0.00       173892  \n",
       "3                 0.00       173892  \n",
       "4                 0.00       173892  \n",
       "5                 0.00       173892  \n",
       "6                 0.00       173892  \n",
       "7                 0.00       173892  \n",
       "8                 0.00       173892  \n",
       "9                 0.00       173892  \n",
       "10                0.00       173892  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check summary\n",
    "\n",
    "summary(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Although these have been fixed on the previous process, seems that there are some `dtypes` that are not proper, there are also a missing values on *comments_tokenized* feature, and check the previous matter regarding the *no description comments*. Therefore once again I'll clean the data on preprocessing first before going on text cleaning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>listing_id</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>reviewer_id</th>\n",
       "      <th>reviewer_name</th>\n",
       "      <th>comments</th>\n",
       "      <th>comments_cleaned</th>\n",
       "      <th>comments_tokenized</th>\n",
       "      <th>compound_score</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>topics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>156926</td>\n",
       "      <td>67089326</td>\n",
       "      <td>2016-03-26</td>\n",
       "      <td>54401579</td>\n",
       "      <td>Raquel</td>\n",
       "      <td>Un sitio excelente, comodo, limpio y en una zo...</td>\n",
       "      <td>un sitio excelente comodo limpio en una zona a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>home beautiful perfect space host</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>156926</td>\n",
       "      <td>108262942</td>\n",
       "      <td>2016-10-15</td>\n",
       "      <td>50062310</td>\n",
       "      <td>Chen-Yi</td>\n",
       "      <td>Everything was described correctly!</td>\n",
       "      <td>everything described correctly</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>home beautiful perfect space host</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>156926</td>\n",
       "      <td>363795585</td>\n",
       "      <td>2018-12-29</td>\n",
       "      <td>55670211</td>\n",
       "      <td>Kathryn</td>\n",
       "      <td>Thanks for having me</td>\n",
       "      <td>thanks</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>home beautiful perfect space host</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>156926</td>\n",
       "      <td>454126304</td>\n",
       "      <td>2019-05-17</td>\n",
       "      <td>64777113</td>\n",
       "      <td>Ashton</td>\n",
       "      <td>I enjoyed my stay. If I am ever in Asheville a...</td>\n",
       "      <td>enjoyed stay ever asheville would definitely stay</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>home beautiful perfect space host</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>156926</td>\n",
       "      <td>467554866</td>\n",
       "      <td>2019-06-10</td>\n",
       "      <td>112577954</td>\n",
       "      <td>Axelle</td>\n",
       "      <td>Excellente auberge de jeunesse! Je recommande!!</td>\n",
       "      <td>excellente auberge de jeunesse je recommande</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>home beautiful perfect space host</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173535</th>\n",
       "      <td>45023214</td>\n",
       "      <td>666276487</td>\n",
       "      <td>2020-09-20</td>\n",
       "      <td>159345242</td>\n",
       "      <td>Jonathan</td>\n",
       "      <td>This house was very nice and well kept up. It ...</td>\n",
       "      <td>house nice well kept exactly expected would de...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>home beautiful perfect space host</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173802</th>\n",
       "      <td>45623198</td>\n",
       "      <td>701646936</td>\n",
       "      <td>2020-10-18</td>\n",
       "      <td>168239689</td>\n",
       "      <td>Alex</td>\n",
       "      <td>Very clean and cozy!</td>\n",
       "      <td>clean cozy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>home beautiful perfect space host</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173832</th>\n",
       "      <td>45684376</td>\n",
       "      <td>705149781</td>\n",
       "      <td>2020-10-30</td>\n",
       "      <td>50451438</td>\n",
       "      <td>Taliyah</td>\n",
       "      <td>Very cozy</td>\n",
       "      <td>cozy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>home beautiful perfect space host</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173875</th>\n",
       "      <td>45846658</td>\n",
       "      <td>703921445</td>\n",
       "      <td>2020-10-25</td>\n",
       "      <td>371770957</td>\n",
       "      <td>Alexander</td>\n",
       "      <td>Very cozy space and thoughtful host!</td>\n",
       "      <td>cozy space thoughtful host</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>home beautiful perfect space host</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173885</th>\n",
       "      <td>45970476</td>\n",
       "      <td>704259347</td>\n",
       "      <td>2020-10-26</td>\n",
       "      <td>365463203</td>\n",
       "      <td>Kenneth</td>\n",
       "      <td>Nothing</td>\n",
       "      <td>nothing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>home beautiful perfect space host</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1187 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        listing_id         id        date  reviewer_id reviewer_name  \\\n",
       "471         156926   67089326  2016-03-26     54401579        Raquel   \n",
       "489         156926  108262942  2016-10-15     50062310       Chen-Yi   \n",
       "571         156926  363795585  2018-12-29     55670211       Kathryn   \n",
       "592         156926  454126304  2019-05-17     64777113        Ashton   \n",
       "595         156926  467554866  2019-06-10    112577954        Axelle   \n",
       "...            ...        ...         ...          ...           ...   \n",
       "173535    45023214  666276487  2020-09-20    159345242      Jonathan   \n",
       "173802    45623198  701646936  2020-10-18    168239689          Alex   \n",
       "173832    45684376  705149781  2020-10-30     50451438       Taliyah   \n",
       "173875    45846658  703921445  2020-10-25    371770957     Alexander   \n",
       "173885    45970476  704259347  2020-10-26    365463203       Kenneth   \n",
       "\n",
       "                                                 comments  \\\n",
       "471     Un sitio excelente, comodo, limpio y en una zo...   \n",
       "489                   Everything was described correctly!   \n",
       "571                                  Thanks for having me   \n",
       "592     I enjoyed my stay. If I am ever in Asheville a...   \n",
       "595       Excellente auberge de jeunesse! Je recommande!!   \n",
       "...                                                   ...   \n",
       "173535  This house was very nice and well kept up. It ...   \n",
       "173802                               Very clean and cozy!   \n",
       "173832                                          Very cozy   \n",
       "173875               Very cozy space and thoughtful host!   \n",
       "173885                                            Nothing   \n",
       "\n",
       "                                         comments_cleaned comments_tokenized  \\\n",
       "471     un sitio excelente comodo limpio en una zona a...                NaN   \n",
       "489                        everything described correctly                NaN   \n",
       "571                                                thanks                NaN   \n",
       "592     enjoyed stay ever asheville would definitely stay                NaN   \n",
       "595          excellente auberge de jeunesse je recommande                NaN   \n",
       "...                                                   ...                ...   \n",
       "173535  house nice well kept exactly expected would de...                NaN   \n",
       "173802                                         clean cozy                NaN   \n",
       "173832                                               cozy                NaN   \n",
       "173875                         cozy space thoughtful host                NaN   \n",
       "173885                                            nothing                NaN   \n",
       "\n",
       "        compound_score sentiment                             topics  \n",
       "471                0.0   neutral  home beautiful perfect space host  \n",
       "489                0.0   neutral  home beautiful perfect space host  \n",
       "571                0.0   neutral  home beautiful perfect space host  \n",
       "592                0.0   neutral  home beautiful perfect space host  \n",
       "595                0.0   neutral  home beautiful perfect space host  \n",
       "...                ...       ...                                ...  \n",
       "173535             0.0   neutral  home beautiful perfect space host  \n",
       "173802             0.0   neutral  home beautiful perfect space host  \n",
       "173832             0.0   neutral  home beautiful perfect space host  \n",
       "173875             0.0   neutral  home beautiful perfect space host  \n",
       "173885             0.0   neutral  home beautiful perfect space host  \n",
       "\n",
       "[1187 rows x 11 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the missing values\n",
    "\n",
    "df[df['comments_tokenized'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Seeing above missing values, I think the review itself still considered proper. But for modelling purpose, I'll drop these instead so that these data will not disturb the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see the anomaly\n",
    "\n",
    "anomaly = df[(df['comments']=='No Description') | (df['comments_cleaned']=='No Description')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>listing_id</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>reviewer_id</th>\n",
       "      <th>reviewer_name</th>\n",
       "      <th>comments</th>\n",
       "      <th>comments_cleaned</th>\n",
       "      <th>comments_tokenized</th>\n",
       "      <th>compound_score</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>topics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>155305</td>\n",
       "      <td>286556497</td>\n",
       "      <td>2018-07-06</td>\n",
       "      <td>199962397</td>\n",
       "      <td>Leif</td>\n",
       "      <td>A</td>\n",
       "      <td>No Description</td>\n",
       "      <td>description</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>home beautiful perfect space host</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>156926</td>\n",
       "      <td>552755567</td>\n",
       "      <td>2019-10-22</td>\n",
       "      <td>7946489</td>\n",
       "      <td>Юлия</td>\n",
       "      <td>Время проведенное с Дарьей было увлекательным ...</td>\n",
       "      <td>No Description</td>\n",
       "      <td>description</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>home beautiful perfect space host</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>156926</td>\n",
       "      <td>560000486</td>\n",
       "      <td>2019-11-05</td>\n",
       "      <td>61670213</td>\n",
       "      <td>Oxana</td>\n",
       "      <td>Очень интересно!! не жалею о новом опыте, и вп...</td>\n",
       "      <td>No Description</td>\n",
       "      <td>description</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>home beautiful perfect space host</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1292</th>\n",
       "      <td>259576</td>\n",
       "      <td>203258198</td>\n",
       "      <td>2017-10-14</td>\n",
       "      <td>149002825</td>\n",
       "      <td>David</td>\n",
       "      <td>.</td>\n",
       "      <td>No Description</td>\n",
       "      <td>description</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>home beautiful perfect space host</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1386</th>\n",
       "      <td>259576</td>\n",
       "      <td>359959590</td>\n",
       "      <td>2018-12-18</td>\n",
       "      <td>229443928</td>\n",
       "      <td>Raphael</td>\n",
       "      <td>.</td>\n",
       "      <td>No Description</td>\n",
       "      <td>description</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>home beautiful perfect space host</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      listing_id         id        date  reviewer_id reviewer_name  \\\n",
       "254       155305  286556497  2018-07-06    199962397          Leif   \n",
       "633       156926  552755567  2019-10-22      7946489          Юлия   \n",
       "638       156926  560000486  2019-11-05     61670213         Oxana   \n",
       "1292      259576  203258198  2017-10-14    149002825         David   \n",
       "1386      259576  359959590  2018-12-18    229443928       Raphael   \n",
       "\n",
       "                                               comments comments_cleaned  \\\n",
       "254                                                   A   No Description   \n",
       "633   Время проведенное с Дарьей было увлекательным ...   No Description   \n",
       "638   Очень интересно!! не жалею о новом опыте, и вп...   No Description   \n",
       "1292                                                  .   No Description   \n",
       "1386                                                  .   No Description   \n",
       "\n",
       "     comments_tokenized  compound_score sentiment  \\\n",
       "254         description             0.0   neutral   \n",
       "633         description             0.0   neutral   \n",
       "638         description             0.0   neutral   \n",
       "1292        description             0.0   neutral   \n",
       "1386        description             0.0   neutral   \n",
       "\n",
       "                                 topics  \n",
       "254   home beautiful perfect space host  \n",
       "633   home beautiful perfect space host  \n",
       "638   home beautiful perfect space host  \n",
       "1292  home beautiful perfect space host  \n",
       "1386  home beautiful perfect space host  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show anomaly\n",
    "\n",
    "anomaly.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of anomaly : 0.14%\n"
     ]
    }
   ],
   "source": [
    "# see percentages\n",
    "\n",
    "print(f'Length of anomaly : {round(len(anomaly)/len(df)*100, 2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 237 entries, 254 to 173730\n",
      "Data columns (total 11 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   listing_id          237 non-null    int64  \n",
      " 1   id                  237 non-null    int64  \n",
      " 2   date                237 non-null    object \n",
      " 3   reviewer_id         237 non-null    int64  \n",
      " 4   reviewer_name       237 non-null    object \n",
      " 5   comments            237 non-null    object \n",
      " 6   comments_cleaned    237 non-null    object \n",
      " 7   comments_tokenized  237 non-null    object \n",
      " 8   compound_score      237 non-null    float64\n",
      " 9   sentiment           237 non-null    object \n",
      " 10  topics              237 non-null    object \n",
      "dtypes: float64(1), int64(3), object(7)\n",
      "memory usage: 22.2+ KB\n"
     ]
    }
   ],
   "source": [
    "anomaly.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The anomaly are just about 0.14% of the total data. I think it's still safe to drop these values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping the anomaly\n",
    "\n",
    "df = df[~((df['comments'].isin(anomaly['comments'])) | (df['comments_tokenized'].isin(anomaly['comments_tokenized'])))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop missing values\n",
    "\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixing columns dtpes\n",
    "\n",
    "for i in df.columns:\n",
    "    if i == 'listing_id' or i == 'id' or i == 'reviewer_id':\n",
    "        df[i] = df[i].astype(np.object)\n",
    "    elif i == 'date' :\n",
    "        df[i] = pd.to_datetime(df[i])\n",
    "    else : \n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>dtypes</th>\n",
       "      <th>unique_count</th>\n",
       "      <th>missing_values</th>\n",
       "      <th>missing_percentage</th>\n",
       "      <th>total_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>listing_id</td>\n",
       "      <td>object</td>\n",
       "      <td>2042</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>172465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id</td>\n",
       "      <td>object</td>\n",
       "      <td>172465</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>172465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>date</td>\n",
       "      <td>datetime64[ns]</td>\n",
       "      <td>2904</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>172465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>reviewer_id</td>\n",
       "      <td>object</td>\n",
       "      <td>157219</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>172465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>reviewer_name</td>\n",
       "      <td>object</td>\n",
       "      <td>16166</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>172465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>comments</td>\n",
       "      <td>object</td>\n",
       "      <td>169865</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>172465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>comments_cleaned</td>\n",
       "      <td>object</td>\n",
       "      <td>167552</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>172465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>comments_tokenized</td>\n",
       "      <td>object</td>\n",
       "      <td>161618</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>172465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>compound_score</td>\n",
       "      <td>float64</td>\n",
       "      <td>1841</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>172465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sentiment</td>\n",
       "      <td>object</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>172465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>topics</td>\n",
       "      <td>object</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>172465</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                column          dtypes  unique_count  missing_values  \\\n",
       "0           listing_id          object          2042               0   \n",
       "1                   id          object        172465               0   \n",
       "2                 date  datetime64[ns]          2904               0   \n",
       "3          reviewer_id          object        157219               0   \n",
       "4        reviewer_name          object         16166               0   \n",
       "5             comments          object        169865               0   \n",
       "6     comments_cleaned          object        167552               0   \n",
       "7   comments_tokenized          object        161618               0   \n",
       "8       compound_score         float64          1841               0   \n",
       "9            sentiment          object             3               0   \n",
       "10              topics          object             5               0   \n",
       "\n",
       "    missing_percentage  total_count  \n",
       "0                  0.0       172465  \n",
       "1                  0.0       172465  \n",
       "2                  0.0       172465  \n",
       "3                  0.0       172465  \n",
       "4                  0.0       172465  \n",
       "5                  0.0       172465  \n",
       "6                  0.0       172465  \n",
       "7                  0.0       172465  \n",
       "8                  0.0       172465  \n",
       "9                  0.0       172465  \n",
       "10                 0.0       172465  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check summary\n",
    "\n",
    "summary(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Now, I'll go to the modelling part. But since this will be a **multiclass classification** and the data are quite **imbalanced**, I'll be using **Gaussian Naive Bayes and Stochastic Gradient Descent** to kind of tackle this, and we might need to tweak and resample it somehow later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    164534\n",
       "neutral       6861\n",
       "negative      1070\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the imbalanced target\n",
    "\n",
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODELLING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> A problem with imbalanced classification is that **there are too few examples of the minority class for a model to effectively learn the decision boundary**. One way **to solve this problem is to oversample the examples in the minority class**. This can be achieved by simply duplicating examples from the minority class in the training dataset prior to fitting a model. This can balance the class distribution but does not provide any additional information to the model.\n",
    "\n",
    "> **Perhaps the most widely used approach to synthesizing new examples is called the Synthetic Minority Oversampling TEchnique, or SMOTE**. It works by selecting examples that are close in the feature space, drawing a line between the examples in the feature space and drawing a new sample at a point along that line. Specifically, a random example from the minority class is first chosen. Then k of the nearest neighbors for that example are found (typically k=5). A randomly selected neighbor is chosen and a synthetic example is created at a randomly selected point between the two examples in feature space.\n",
    "\n",
    "> We will use this method below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label the target\n",
    "\n",
    "df['sentiment'] = LabelEncoder().fit_transform(df['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.39453716 0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.09858178]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.26343102]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# set the dependent\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features = 100)\n",
    "tf_idf = vectorizer.fit_transform(df['comments_cleaned']).toarray()\n",
    "print(tf_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(tf_idf, df['sentiment'], test_size=0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GAUSSIAN NAIVE BAYES MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Naive Bayes can be extended to real-valued attributes, most commonly by assuming a **Gaussian distribution**. This extension of naive Bayes is called **Gaussian Naive Bayes**. Other functions can be used to estimate the distribution of the data, but the Gaussian (or Normal distribution) is the easiest to work with because we only need to estimate the mean and the standard deviation from our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize model\n",
    "\n",
    "model_gnb = GaussianNB()\n",
    "model_gnb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  109    62    35]\n",
      " [  230   939   188]\n",
      " [ 3574  6532 22824]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.03      0.53      0.05       206\n",
      "           1       0.12      0.69      0.21      1357\n",
      "           2       0.99      0.69      0.82     32930\n",
      "\n",
      "    accuracy                           0.69     34493\n",
      "   macro avg       0.38      0.64      0.36     34493\n",
      "weighted avg       0.95      0.69      0.79     34493\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predict and see the classification report\n",
    "\n",
    "y_pred_gnb = model_gnb.predict(X_test)\n",
    "print(confusion_matrix(y_test,y_pred_gnb))\n",
    "print(classification_report(y_test,y_pred_gnb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Now we can see the model prediction are quite bad. I'll try the same model, but using **SMOTE**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(268712, 100) (268712,)\n"
     ]
    }
   ],
   "source": [
    "# set and apply SMOTE\n",
    "\n",
    "smote = SMOTE('minority')\n",
    "X_sm, y_sm = smote.fit_sample(X_train, y_train)\n",
    "print(X_sm.shape, y_sm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize model with oversampled data\n",
    "\n",
    "model_gnb.fit(X_sm, y_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   98    57    51]\n",
      " [  300   844   213]\n",
      " [ 2434  6486 24010]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.03      0.48      0.06       206\n",
      "           1       0.11      0.62      0.19      1357\n",
      "           2       0.99      0.73      0.84     32930\n",
      "\n",
      "    accuracy                           0.72     34493\n",
      "   macro avg       0.38      0.61      0.37     34493\n",
      "weighted avg       0.95      0.72      0.81     34493\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predict and see the classification report with oversampled data\n",
    "\n",
    "y_pred_gnb_sm = model_gnb.predict(X_test)\n",
    "print(confusion_matrix(y_test,y_pred_gnb_sm))\n",
    "print(classification_report(y_test,y_pred_gnb_sm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Although there are some visible improvement, we can say that this model prediction are still bad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STOCHASTIC GRADIENT DESCENT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Stochastic Gradient Descent (SGD)** is an iterative method for optimizing an objective function with suitable smoothness properties (e.g. differentiable or subdifferentiable). It is a **Linear classifiers (SVM, logistic regression, a.o.) with SGD training**. This estimator **implements regularized linear models with stochastic gradient descent (SGD) learning** : the gradient of the loss is estimated each sample at a time and the model is updated along the way with a decreasing strength schedule / learning rate. SGD allows minibatch (online/out-of-core) learning, see the partial_fit method. For best results using the default learning rate schedule, the data should have zero mean and unit variance.\n",
    "\n",
    "> This implementation works with data represented as dense or sparse arrays of floating point values for the features. The model it fits can be controlled with the loss parameter. **By default, it fits a Linear Support Vector Machine (SVM)**. And Linear SVM is **widely regarded as one of the best text classification algorithms**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(class_weight='balanced', random_state=42)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize model \n",
    "\n",
    "model_sgd = SGDClassifier(random_state=42, class_weight='balanced')\n",
    "model_sgd.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   79    54    73]\n",
      " [  151   736   470]\n",
      " [  584  1040 31306]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.10      0.38      0.15       206\n",
      "           1       0.40      0.54      0.46      1357\n",
      "           2       0.98      0.95      0.97     32930\n",
      "\n",
      "    accuracy                           0.93     34493\n",
      "   macro avg       0.49      0.63      0.53     34493\n",
      "weighted avg       0.95      0.93      0.94     34493\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predict and see the classification report\n",
    "\n",
    "y_pred_sgd = model_sgd.predict(X_test)\n",
    "print(confusion_matrix(y_test,y_pred_sgd))\n",
    "print(classification_report(y_test,y_pred_sgd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We can see that using **weighted class** this model **proved to be far better than naive bayes model** in terms of **accuracy and f1 score**. But I'll try to implement SMOTE to see whether it can be improved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(class_weight='balanced', random_state=42)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize model with oversampled data\n",
    "\n",
    "model_sgd.fit(X_sm, y_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  152    17    37]\n",
      " [  714   339   304]\n",
      " [ 2770   899 29261]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.04      0.74      0.08       206\n",
      "           1       0.27      0.25      0.26      1357\n",
      "           2       0.99      0.89      0.94     32930\n",
      "\n",
      "    accuracy                           0.86     34493\n",
      "   macro avg       0.43      0.63      0.42     34493\n",
      "weighted avg       0.95      0.86      0.90     34493\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predict and see the classification report with oversampled data\n",
    "\n",
    "y_pred_sgd_sm = model_sgd.predict(X_test)\n",
    "print(confusion_matrix(y_test,y_pred_sgd_sm))\n",
    "print(classification_report(y_test,y_pred_sgd_sm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Although it's quite good, it seems that using SMOTE rather decreasing its accuracy and f1 score. Therefore, I'll go with the previous sample for hyperparameter tuning on the next notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump to new dataframe\n",
    "\n",
    "df.to_csv('asheville-reviews-tuning.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REFERENCES \n",
    "\n",
    ">- https://towardsdatascience.com/multi-class-text-classification-model-comparison-and-selection-5eb066197568\n",
    ">- https://machinelearningmastery.com/smote-oversampling-for-imbalanced-classification/\n",
    ">- https://machinelearningmastery.com/naive-bayes-for-machine-learning/#:~:text=This%20extension%20of%20naive%20Bayes,deviation%20from%20your%20training%20data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
