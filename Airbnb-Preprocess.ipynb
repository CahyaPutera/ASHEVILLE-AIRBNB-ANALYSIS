{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASHEVILLE AIRBNB SENTIMENT ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The purpose of this report is **to analyze customer reviews for Airbnb on Asheville, North Carolina, United States**. And act as a stepping stone **to know what the customers think of the service offered by Asheville's Airbnb, and this analysis could help to know if the hosts are providing good customer service or not**. The analysis progress would be separated on several notebook, and will cover from *data preprocessing, text preprocessing, topic modelling, visualization, model building, to model testing*. \n",
    "\n",
    "> This notebook specifically will only cover the **DATA PREPROCESSING** part.\n",
    "\n",
    "> The dataset contains the **detailed review data for listings in Asheville, North Carolina** compiled on **08 November, 2020**. The data are from the **Inside Airbnb site**, it is sourced from publicly available information, from the Airbnb site. The data has been analyzed, cleansed and aggregated where appropriate to faciliate public discussion. More on this data, and other similar data refers to this [link](http://insideairbnb.com/get-the-data.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORT LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data wrangling\n",
    "\n",
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# data visualization\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# text processing\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "# filter warning\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OVERVIEW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "\n",
    "df = pd.read_csv('asheville-reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>listing_id</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>reviewer_id</th>\n",
       "      <th>reviewer_name</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>108061</td>\n",
       "      <td>553741</td>\n",
       "      <td>2011-09-21</td>\n",
       "      <td>822907</td>\n",
       "      <td>Pedro &amp; Katie</td>\n",
       "      <td>Lisa is superb hostess, she will treat you lik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>108061</td>\n",
       "      <td>683278</td>\n",
       "      <td>2011-11-01</td>\n",
       "      <td>236064</td>\n",
       "      <td>Tim</td>\n",
       "      <td>This was a lovely little place walking distanc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>108061</td>\n",
       "      <td>714889</td>\n",
       "      <td>2011-11-13</td>\n",
       "      <td>1382707</td>\n",
       "      <td>Shane</td>\n",
       "      <td>Lisa was very nice to work with.  However, we ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>108061</td>\n",
       "      <td>1766157</td>\n",
       "      <td>2012-07-21</td>\n",
       "      <td>416731</td>\n",
       "      <td>Brenda</td>\n",
       "      <td>I feel very lucky to have found this beautiful...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>108061</td>\n",
       "      <td>2033065</td>\n",
       "      <td>2012-08-19</td>\n",
       "      <td>1858880</td>\n",
       "      <td>Lindsey</td>\n",
       "      <td>Great roomy little apartment, beautiful privat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   listing_id       id        date  reviewer_id  reviewer_name  \\\n",
       "0      108061   553741  2011-09-21       822907  Pedro & Katie   \n",
       "1      108061   683278  2011-11-01       236064            Tim   \n",
       "2      108061   714889  2011-11-13      1382707          Shane   \n",
       "3      108061  1766157  2012-07-21       416731         Brenda   \n",
       "4      108061  2033065  2012-08-19      1858880        Lindsey   \n",
       "\n",
       "                                            comments  \n",
       "0  Lisa is superb hostess, she will treat you lik...  \n",
       "1  This was a lovely little place walking distanc...  \n",
       "2  Lisa was very nice to work with.  However, we ...  \n",
       "3  I feel very lucky to have found this beautiful...  \n",
       "4  Great roomy little apartment, beautiful privat...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show top 5\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 173892 entries, 0 to 173891\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Non-Null Count   Dtype \n",
      "---  ------         --------------   ----- \n",
      " 0   listing_id     173892 non-null  int64 \n",
      " 1   id             173892 non-null  int64 \n",
      " 2   date           173892 non-null  object\n",
      " 3   reviewer_id    173892 non-null  int64 \n",
      " 4   reviewer_name  173892 non-null  object\n",
      " 5   comments       173838 non-null  object\n",
      "dtypes: int64(3), object(3)\n",
      "memory usage: 8.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# check info\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to check data summary\n",
    "\n",
    "def summary(df):\n",
    "    \n",
    "    columns = df.columns.to_list()\n",
    "    \n",
    "    dtypes = []\n",
    "    unique_counts = []\n",
    "    missing_counts = []\n",
    "    missing_percentages = []\n",
    "    total_counts = [df.shape[0]] * len(columns)\n",
    "\n",
    "    for col in columns:\n",
    "        dtype = str(df[col].dtype)\n",
    "        dtypes.append(dtype)\n",
    "        unique_count = df[col].nunique()\n",
    "        unique_counts.append(unique_count)\n",
    "        missing_count = df[col].isnull().sum()\n",
    "        missing_counts.append(missing_count)\n",
    "        missing_percentage = round((missing_count/df.shape[0]) * 100, 2)\n",
    "        missing_percentages.append(missing_percentage)\n",
    "\n",
    "    df_summary = pd.DataFrame({\n",
    "        \"column\": columns,\n",
    "        \"dtypes\": dtypes,\n",
    "        \"unique_count\": unique_counts,\n",
    "        \"missing_values\": missing_counts,\n",
    "        \"missing_percentage\": missing_percentages,\n",
    "        \"total_count\": total_counts,\n",
    "    })\n",
    "\n",
    "    return df_summary.sort_values(by=\"missing_percentage\", ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>dtypes</th>\n",
       "      <th>unique_count</th>\n",
       "      <th>missing_values</th>\n",
       "      <th>missing_percentage</th>\n",
       "      <th>total_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>comments</td>\n",
       "      <td>object</td>\n",
       "      <td>170970</td>\n",
       "      <td>54</td>\n",
       "      <td>0.03</td>\n",
       "      <td>173892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>listing_id</td>\n",
       "      <td>int64</td>\n",
       "      <td>2044</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>173892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id</td>\n",
       "      <td>int64</td>\n",
       "      <td>173892</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>173892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>date</td>\n",
       "      <td>object</td>\n",
       "      <td>2904</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>173892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>reviewer_id</td>\n",
       "      <td>int64</td>\n",
       "      <td>158449</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>173892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>reviewer_name</td>\n",
       "      <td>object</td>\n",
       "      <td>16279</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>173892</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          column  dtypes  unique_count  missing_values  missing_percentage  \\\n",
       "0       comments  object        170970              54                0.03   \n",
       "1     listing_id   int64          2044               0                0.00   \n",
       "2             id   int64        173892               0                0.00   \n",
       "3           date  object          2904               0                0.00   \n",
       "4    reviewer_id   int64        158449               0                0.00   \n",
       "5  reviewer_name  object         16279               0                0.00   \n",
       "\n",
       "   total_count  \n",
       "0       173892  \n",
       "1       173892  \n",
       "2       173892  \n",
       "3       173892  \n",
       "4       173892  \n",
       "5       173892  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check summary\n",
    "\n",
    "summary(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> There are some `dtypes` that are not proper, then there are also a missing values on *comments* feature. I'll check on it later. But I'll clean the data on preprocessing first before going on text cleaning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixing columns dtpes\n",
    "\n",
    "for i in df.columns:\n",
    "    if i == 'listing_id' or i == 'id' or i == 'reviewer_id':\n",
    "        df[i] = df[i].astype(np.object)\n",
    "    elif i == 'date' :\n",
    "        df[i] = pd.to_datetime(df[i])\n",
    "    else : \n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 173892 entries, 0 to 173891\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Non-Null Count   Dtype         \n",
      "---  ------         --------------   -----         \n",
      " 0   listing_id     173892 non-null  object        \n",
      " 1   id             173892 non-null  object        \n",
      " 2   date           173892 non-null  datetime64[ns]\n",
      " 3   reviewer_id    173892 non-null  object        \n",
      " 4   reviewer_name  173892 non-null  object        \n",
      " 5   comments       173838 non-null  object        \n",
      "dtypes: datetime64[ns](1), object(5)\n",
      "memory usage: 8.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# check info\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>listing_id</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>reviewer_id</th>\n",
       "      <th>reviewer_name</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11888</th>\n",
       "      <td>1827412</td>\n",
       "      <td>426615038</td>\n",
       "      <td>2019-03-21</td>\n",
       "      <td>247099480</td>\n",
       "      <td>David</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15856</th>\n",
       "      <td>2411109</td>\n",
       "      <td>406175955</td>\n",
       "      <td>2019-01-28</td>\n",
       "      <td>110949606</td>\n",
       "      <td>Josi</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18887</th>\n",
       "      <td>3095136</td>\n",
       "      <td>127198043</td>\n",
       "      <td>2017-01-16</td>\n",
       "      <td>111272759</td>\n",
       "      <td>Ash</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20030</th>\n",
       "      <td>3225871</td>\n",
       "      <td>209550903</td>\n",
       "      <td>2017-11-05</td>\n",
       "      <td>147365729</td>\n",
       "      <td>Andrew</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20390</th>\n",
       "      <td>3314819</td>\n",
       "      <td>52436690</td>\n",
       "      <td>2015-10-29</td>\n",
       "      <td>46496931</td>\n",
       "      <td>Dwight</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30057</th>\n",
       "      <td>5144212</td>\n",
       "      <td>555444539</td>\n",
       "      <td>2019-10-27</td>\n",
       "      <td>4592</td>\n",
       "      <td>Rebecca</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31303</th>\n",
       "      <td>5696919</td>\n",
       "      <td>441087924</td>\n",
       "      <td>2019-04-21</td>\n",
       "      <td>140470172</td>\n",
       "      <td>Michael</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33816</th>\n",
       "      <td>6234618</td>\n",
       "      <td>311153650</td>\n",
       "      <td>2018-08-20</td>\n",
       "      <td>74602012</td>\n",
       "      <td>Eileen</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39678</th>\n",
       "      <td>7556089</td>\n",
       "      <td>441017868</td>\n",
       "      <td>2019-04-21</td>\n",
       "      <td>72106403</td>\n",
       "      <td>Tori</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42045</th>\n",
       "      <td>8051829</td>\n",
       "      <td>339537756</td>\n",
       "      <td>2018-10-21</td>\n",
       "      <td>166411083</td>\n",
       "      <td>Michael</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47456</th>\n",
       "      <td>10632884</td>\n",
       "      <td>247774303</td>\n",
       "      <td>2018-03-29</td>\n",
       "      <td>176359577</td>\n",
       "      <td>Bethany</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52712</th>\n",
       "      <td>12286328</td>\n",
       "      <td>570925775</td>\n",
       "      <td>2019-11-30</td>\n",
       "      <td>224383837</td>\n",
       "      <td>Carlie</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55592</th>\n",
       "      <td>12763722</td>\n",
       "      <td>664674089</td>\n",
       "      <td>2020-09-15</td>\n",
       "      <td>243180828</td>\n",
       "      <td>Stephanie</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56287</th>\n",
       "      <td>12835184</td>\n",
       "      <td>466803001</td>\n",
       "      <td>2019-06-09</td>\n",
       "      <td>60406179</td>\n",
       "      <td>Jamie</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56915</th>\n",
       "      <td>12944995</td>\n",
       "      <td>416394206</td>\n",
       "      <td>2019-02-24</td>\n",
       "      <td>236410626</td>\n",
       "      <td>Kemp</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58111</th>\n",
       "      <td>13112074</td>\n",
       "      <td>328260078</td>\n",
       "      <td>2018-09-25</td>\n",
       "      <td>121268935</td>\n",
       "      <td>Tiffany</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59551</th>\n",
       "      <td>13258472</td>\n",
       "      <td>190984894</td>\n",
       "      <td>2017-09-05</td>\n",
       "      <td>147070219</td>\n",
       "      <td>Jonathan</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62540</th>\n",
       "      <td>13700790</td>\n",
       "      <td>576162833</td>\n",
       "      <td>2019-12-12</td>\n",
       "      <td>224383837</td>\n",
       "      <td>Carlie</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62755</th>\n",
       "      <td>13716891</td>\n",
       "      <td>237080284</td>\n",
       "      <td>2018-02-21</td>\n",
       "      <td>171693783</td>\n",
       "      <td>Adam</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62986</th>\n",
       "      <td>13744589</td>\n",
       "      <td>136111301</td>\n",
       "      <td>2017-03-08</td>\n",
       "      <td>119286986</td>\n",
       "      <td>Ryan</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64911</th>\n",
       "      <td>14352724</td>\n",
       "      <td>557206634</td>\n",
       "      <td>2019-10-31</td>\n",
       "      <td>40817729</td>\n",
       "      <td>Jessica</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66695</th>\n",
       "      <td>14731928</td>\n",
       "      <td>403722588</td>\n",
       "      <td>2019-01-21</td>\n",
       "      <td>236743873</td>\n",
       "      <td>William Edward</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69987</th>\n",
       "      <td>15174633</td>\n",
       "      <td>342296650</td>\n",
       "      <td>2018-10-28</td>\n",
       "      <td>165241867</td>\n",
       "      <td>Nick</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75882</th>\n",
       "      <td>16003488</td>\n",
       "      <td>522800217</td>\n",
       "      <td>2019-09-02</td>\n",
       "      <td>107913345</td>\n",
       "      <td>Zachary</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80754</th>\n",
       "      <td>16846899</td>\n",
       "      <td>703824204</td>\n",
       "      <td>2020-10-25</td>\n",
       "      <td>366913696</td>\n",
       "      <td>Allison</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84920</th>\n",
       "      <td>17726977</td>\n",
       "      <td>434761690</td>\n",
       "      <td>2019-04-08</td>\n",
       "      <td>200002828</td>\n",
       "      <td>Meg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92231</th>\n",
       "      <td>19032051</td>\n",
       "      <td>355347984</td>\n",
       "      <td>2018-12-03</td>\n",
       "      <td>140564550</td>\n",
       "      <td>Kelli</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102654</th>\n",
       "      <td>20697346</td>\n",
       "      <td>334903405</td>\n",
       "      <td>2018-10-10</td>\n",
       "      <td>218919726</td>\n",
       "      <td>Kendra</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102798</th>\n",
       "      <td>20697346</td>\n",
       "      <td>596050544</td>\n",
       "      <td>2020-01-21</td>\n",
       "      <td>39081638</td>\n",
       "      <td>Griffin</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105991</th>\n",
       "      <td>21023689</td>\n",
       "      <td>204518683</td>\n",
       "      <td>2017-10-18</td>\n",
       "      <td>152218408</td>\n",
       "      <td>Pete</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114628</th>\n",
       "      <td>22740737</td>\n",
       "      <td>666459930</td>\n",
       "      <td>2020-09-20</td>\n",
       "      <td>46481617</td>\n",
       "      <td>Olivia</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118997</th>\n",
       "      <td>23480306</td>\n",
       "      <td>263283789</td>\n",
       "      <td>2018-05-11</td>\n",
       "      <td>66119144</td>\n",
       "      <td>Brian</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120535</th>\n",
       "      <td>23563574</td>\n",
       "      <td>347575197</td>\n",
       "      <td>2018-11-11</td>\n",
       "      <td>152478332</td>\n",
       "      <td>Kevin</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122544</th>\n",
       "      <td>23877206</td>\n",
       "      <td>495886035</td>\n",
       "      <td>2019-07-26</td>\n",
       "      <td>196318644</td>\n",
       "      <td>Harrison</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122603</th>\n",
       "      <td>23881173</td>\n",
       "      <td>568600439</td>\n",
       "      <td>2019-11-24</td>\n",
       "      <td>631467</td>\n",
       "      <td>Daniel</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129211</th>\n",
       "      <td>25519478</td>\n",
       "      <td>488880299</td>\n",
       "      <td>2019-07-15</td>\n",
       "      <td>85702374</td>\n",
       "      <td>Tyler</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129774</th>\n",
       "      <td>25882810</td>\n",
       "      <td>448786489</td>\n",
       "      <td>2019-05-05</td>\n",
       "      <td>139871312</td>\n",
       "      <td>Steven</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134030</th>\n",
       "      <td>26910515</td>\n",
       "      <td>705931890</td>\n",
       "      <td>2020-11-01</td>\n",
       "      <td>276377076</td>\n",
       "      <td>Justin</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145388</th>\n",
       "      <td>30654481</td>\n",
       "      <td>555274987</td>\n",
       "      <td>2019-10-27</td>\n",
       "      <td>270866364</td>\n",
       "      <td>Janet</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146882</th>\n",
       "      <td>31219623</td>\n",
       "      <td>601082951</td>\n",
       "      <td>2020-02-02</td>\n",
       "      <td>156938070</td>\n",
       "      <td>Jason</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150796</th>\n",
       "      <td>32415241</td>\n",
       "      <td>540031067</td>\n",
       "      <td>2019-10-02</td>\n",
       "      <td>284363588</td>\n",
       "      <td>Trevor</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152287</th>\n",
       "      <td>32851430</td>\n",
       "      <td>488764729</td>\n",
       "      <td>2019-07-15</td>\n",
       "      <td>265733018</td>\n",
       "      <td>Ayana</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155046</th>\n",
       "      <td>34009815</td>\n",
       "      <td>666774485</td>\n",
       "      <td>2020-09-21</td>\n",
       "      <td>367677779</td>\n",
       "      <td>Kurt</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155169</th>\n",
       "      <td>34038444</td>\n",
       "      <td>702559687</td>\n",
       "      <td>2020-10-21</td>\n",
       "      <td>50518060</td>\n",
       "      <td>Kyle</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159125</th>\n",
       "      <td>35516808</td>\n",
       "      <td>629640709</td>\n",
       "      <td>2020-06-14</td>\n",
       "      <td>293136683</td>\n",
       "      <td>Max</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159379</th>\n",
       "      <td>35578680</td>\n",
       "      <td>643951173</td>\n",
       "      <td>2020-07-29</td>\n",
       "      <td>91907881</td>\n",
       "      <td>Caleb</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162202</th>\n",
       "      <td>37039540</td>\n",
       "      <td>644719650</td>\n",
       "      <td>2020-07-31</td>\n",
       "      <td>212084654</td>\n",
       "      <td>Hannah</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162670</th>\n",
       "      <td>37287365</td>\n",
       "      <td>574821714</td>\n",
       "      <td>2019-12-08</td>\n",
       "      <td>313094044</td>\n",
       "      <td>Serge</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168681</th>\n",
       "      <td>40175865</td>\n",
       "      <td>641109469</td>\n",
       "      <td>2020-07-22</td>\n",
       "      <td>19445390</td>\n",
       "      <td>Emily</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168752</th>\n",
       "      <td>40273960</td>\n",
       "      <td>575542708</td>\n",
       "      <td>2019-12-10</td>\n",
       "      <td>224383837</td>\n",
       "      <td>Carlie</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171055</th>\n",
       "      <td>42330339</td>\n",
       "      <td>640065149</td>\n",
       "      <td>2020-07-19</td>\n",
       "      <td>8574048</td>\n",
       "      <td>Michael</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171388</th>\n",
       "      <td>42669657</td>\n",
       "      <td>702081383</td>\n",
       "      <td>2020-10-19</td>\n",
       "      <td>27971409</td>\n",
       "      <td>Luke</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171531</th>\n",
       "      <td>42980378</td>\n",
       "      <td>626004838</td>\n",
       "      <td>2020-05-24</td>\n",
       "      <td>344372599</td>\n",
       "      <td>Catherine</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172900</th>\n",
       "      <td>44087805</td>\n",
       "      <td>643358257</td>\n",
       "      <td>2020-07-27</td>\n",
       "      <td>356803427</td>\n",
       "      <td>Susan</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       listing_id         id       date reviewer_id   reviewer_name comments\n",
       "11888     1827412  426615038 2019-03-21   247099480           David      NaN\n",
       "15856     2411109  406175955 2019-01-28   110949606            Josi      NaN\n",
       "18887     3095136  127198043 2017-01-16   111272759             Ash      NaN\n",
       "20030     3225871  209550903 2017-11-05   147365729          Andrew      NaN\n",
       "20390     3314819   52436690 2015-10-29    46496931          Dwight      NaN\n",
       "30057     5144212  555444539 2019-10-27        4592         Rebecca      NaN\n",
       "31303     5696919  441087924 2019-04-21   140470172         Michael      NaN\n",
       "33816     6234618  311153650 2018-08-20    74602012          Eileen      NaN\n",
       "39678     7556089  441017868 2019-04-21    72106403            Tori      NaN\n",
       "42045     8051829  339537756 2018-10-21   166411083         Michael      NaN\n",
       "47456    10632884  247774303 2018-03-29   176359577         Bethany      NaN\n",
       "52712    12286328  570925775 2019-11-30   224383837          Carlie      NaN\n",
       "55592    12763722  664674089 2020-09-15   243180828       Stephanie      NaN\n",
       "56287    12835184  466803001 2019-06-09    60406179           Jamie      NaN\n",
       "56915    12944995  416394206 2019-02-24   236410626            Kemp      NaN\n",
       "58111    13112074  328260078 2018-09-25   121268935         Tiffany      NaN\n",
       "59551    13258472  190984894 2017-09-05   147070219        Jonathan      NaN\n",
       "62540    13700790  576162833 2019-12-12   224383837          Carlie      NaN\n",
       "62755    13716891  237080284 2018-02-21   171693783            Adam      NaN\n",
       "62986    13744589  136111301 2017-03-08   119286986            Ryan      NaN\n",
       "64911    14352724  557206634 2019-10-31    40817729         Jessica      NaN\n",
       "66695    14731928  403722588 2019-01-21   236743873  William Edward      NaN\n",
       "69987    15174633  342296650 2018-10-28   165241867            Nick      NaN\n",
       "75882    16003488  522800217 2019-09-02   107913345         Zachary      NaN\n",
       "80754    16846899  703824204 2020-10-25   366913696         Allison      NaN\n",
       "84920    17726977  434761690 2019-04-08   200002828             Meg      NaN\n",
       "92231    19032051  355347984 2018-12-03   140564550           Kelli      NaN\n",
       "102654   20697346  334903405 2018-10-10   218919726          Kendra      NaN\n",
       "102798   20697346  596050544 2020-01-21    39081638         Griffin      NaN\n",
       "105991   21023689  204518683 2017-10-18   152218408            Pete      NaN\n",
       "114628   22740737  666459930 2020-09-20    46481617          Olivia      NaN\n",
       "118997   23480306  263283789 2018-05-11    66119144           Brian      NaN\n",
       "120535   23563574  347575197 2018-11-11   152478332           Kevin      NaN\n",
       "122544   23877206  495886035 2019-07-26   196318644        Harrison      NaN\n",
       "122603   23881173  568600439 2019-11-24      631467          Daniel      NaN\n",
       "129211   25519478  488880299 2019-07-15    85702374           Tyler      NaN\n",
       "129774   25882810  448786489 2019-05-05   139871312          Steven      NaN\n",
       "134030   26910515  705931890 2020-11-01   276377076          Justin      NaN\n",
       "145388   30654481  555274987 2019-10-27   270866364           Janet      NaN\n",
       "146882   31219623  601082951 2020-02-02   156938070           Jason      NaN\n",
       "150796   32415241  540031067 2019-10-02   284363588          Trevor      NaN\n",
       "152287   32851430  488764729 2019-07-15   265733018           Ayana      NaN\n",
       "155046   34009815  666774485 2020-09-21   367677779            Kurt      NaN\n",
       "155169   34038444  702559687 2020-10-21    50518060            Kyle      NaN\n",
       "159125   35516808  629640709 2020-06-14   293136683             Max      NaN\n",
       "159379   35578680  643951173 2020-07-29    91907881           Caleb      NaN\n",
       "162202   37039540  644719650 2020-07-31   212084654          Hannah      NaN\n",
       "162670   37287365  574821714 2019-12-08   313094044           Serge      NaN\n",
       "168681   40175865  641109469 2020-07-22    19445390           Emily      NaN\n",
       "168752   40273960  575542708 2019-12-10   224383837          Carlie      NaN\n",
       "171055   42330339  640065149 2020-07-19     8574048         Michael      NaN\n",
       "171388   42669657  702081383 2020-10-19    27971409            Luke      NaN\n",
       "171531   42980378  626004838 2020-05-24   344372599       Catherine      NaN\n",
       "172900   44087805  643358257 2020-07-27   356803427           Susan      NaN"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check missing values\n",
    "\n",
    "df[df['comments'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing values\n",
    "\n",
    "df['comments'].fillna('No Description', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "listing_id       0\n",
       "id               0\n",
       "date             0\n",
       "reviewer_id      0\n",
       "reviewer_name    0\n",
       "comments         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check missing values\n",
    "\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Now that everything is properly cleaned. I'll continue to text processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEXT PROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> To start with, I'll clean the text on *comments* features by doing * case folding* and *tokenizing* as well as *removing stopwords* on the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to clean text\n",
    "\n",
    "def clean_text(data, stopword):\n",
    "    \n",
    "    # casefolding\n",
    "    data = [i.lower() for i in data]\n",
    "    data = [' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|\\d+\", \" \", i).split()) for i in data]\n",
    "    res = ' '.join(data) \n",
    "\n",
    "    # tokenizing \n",
    "    word_tokens = word_tokenize(res)    \n",
    "    res = ' '.join([i for i in word_tokens if not i in stopword])\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set stopword\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# text cleaning\n",
    "\n",
    "comment_filtered = []\n",
    "for i in df['comments']:\n",
    "    comment_filtered.append(clean_text([i], stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lisa superb hostess treat like family provide coziest little home asheville definitely enhance experience magical town like eco retreat private sunny apartment neat little flat need people place impeccable lovely neighborhood hardly beat one'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check filtered comment\n",
    "\n",
    "comment_filtered[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new feature to store cleaned text\n",
    "\n",
    "df['comments_cleaned'] = comment_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>listing_id</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>reviewer_id</th>\n",
       "      <th>reviewer_name</th>\n",
       "      <th>comments</th>\n",
       "      <th>comments_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>108061</td>\n",
       "      <td>553741</td>\n",
       "      <td>2011-09-21</td>\n",
       "      <td>822907</td>\n",
       "      <td>Pedro &amp; Katie</td>\n",
       "      <td>Lisa is superb hostess, she will treat you lik...</td>\n",
       "      <td>lisa superb hostess treat like family provide ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>108061</td>\n",
       "      <td>683278</td>\n",
       "      <td>2011-11-01</td>\n",
       "      <td>236064</td>\n",
       "      <td>Tim</td>\n",
       "      <td>This was a lovely little place walking distanc...</td>\n",
       "      <td>lovely little place walking distance downtown ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>108061</td>\n",
       "      <td>714889</td>\n",
       "      <td>2011-11-13</td>\n",
       "      <td>1382707</td>\n",
       "      <td>Shane</td>\n",
       "      <td>Lisa was very nice to work with.  However, we ...</td>\n",
       "      <td>lisa nice work however realize house old norma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>108061</td>\n",
       "      <td>1766157</td>\n",
       "      <td>2012-07-21</td>\n",
       "      <td>416731</td>\n",
       "      <td>Brenda</td>\n",
       "      <td>I feel very lucky to have found this beautiful...</td>\n",
       "      <td>feel lucky found beautiful home asheville quie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>108061</td>\n",
       "      <td>2033065</td>\n",
       "      <td>2012-08-19</td>\n",
       "      <td>1858880</td>\n",
       "      <td>Lindsey</td>\n",
       "      <td>Great roomy little apartment, beautiful privat...</td>\n",
       "      <td>great roomy little apartment beautiful private...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  listing_id       id       date reviewer_id  reviewer_name  \\\n",
       "0     108061   553741 2011-09-21      822907  Pedro & Katie   \n",
       "1     108061   683278 2011-11-01      236064            Tim   \n",
       "2     108061   714889 2011-11-13     1382707          Shane   \n",
       "3     108061  1766157 2012-07-21      416731         Brenda   \n",
       "4     108061  2033065 2012-08-19     1858880        Lindsey   \n",
       "\n",
       "                                            comments  \\\n",
       "0  Lisa is superb hostess, she will treat you lik...   \n",
       "1  This was a lovely little place walking distanc...   \n",
       "2  Lisa was very nice to work with.  However, we ...   \n",
       "3  I feel very lucky to have found this beautiful...   \n",
       "4  Great roomy little apartment, beautiful privat...   \n",
       "\n",
       "                                    comments_cleaned  \n",
       "0  lisa superb hostess treat like family provide ...  \n",
       "1  lovely little place walking distance downtown ...  \n",
       "2  lisa nice work however realize house old norma...  \n",
       "3  feel lucky found beautiful home asheville quie...  \n",
       "4  great roomy little apartment beautiful private...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show dataframe\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Next, I'll drop this cleaned data to new dataframe to be used on the next part. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop to new dataframe\n",
    "\n",
    "df.to_csv('asheville-reviews-clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REFERENCES\n",
    "\n",
    ">- https://towardsdatascience.com/stemming-vs-lemmatization-2daddabcb221?_branch_match_id=835004835328579359\n",
    ">- https://towardsdatascience.com/stemming-lemmatization-what-ba782b7c0bd8"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
